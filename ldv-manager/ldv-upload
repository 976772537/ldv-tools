#!/usr/bin/env ruby
require 'rubygems'
require 'active_record'
require 'find'
require 'open3'
require 'logger'
require 'rexml/document'
require 'fileutils'
require 'optparse'

ENV['LDV_SRVHOME'] ||= File.expand_path("../",File.dirname(__FILE__))
manhome = File.join(ENV['LDV_SRVHOME'],"ldv-manager")

# Due to a huge size of a log, it's not useful to print warnings as they appear.  Instead, we just save them here.
warnings = []

print_warnings = proc do
	unless warnings.empty?
		$stderr.puts "\nWARNINGS (#{warnings.length}):"
		warnings.each {|w| $stderr.puts w }
		$stderr.puts ""
	end
end

Kernel.trap('INT', print_warnings)

require File.join(manhome,"upload_utils.rb")
ldv_db_connect

# We should connect before we load our data model
require File.join(manhome,"results_model.rb")

# All models were loaded in results_model.rb.  Now we just add a couple of methods that regard loading them from report
#
# Convenience functions are in upload_utils.rb


## Ancillary commands for loading models from XML

class Task
	# Get date and time of a task from a special "timestamp" tag.  It should be set in report-fixup correspondingly!
	def self.process_timestamp_tag(timestamp_tag)
		# List of tags to read
		tags = %w{sec min hour mday mon year wday yday isdst}
		# Read tags into tag->value hash
		d = {}
		tags.each {|tn| d[tn] = (timestamp_tag/tn).to_i}
		# Return date
		DateTime.civil(d['year'], d['mon'], d['mday'], d['hour'], d['min'], d['sec'])
	end

	def self.from_xml(tag)
		# Get parameters that may characterize the task
		task_id = ENV['LDV_TASK_ID'] || tag.field("task_id")
		task_name = ENV['LDV_TASK_NAME'] || tag.field("task_name")
		task_username = ENV['LDV_TASK_USERNAME'] || tag/"username"
		if ENV['LDV_TASK_TIMESTAMP']
			begin
				task_timestamp = DateTime.parse(ENV['LDV_TASK_TIMESTAMP'])
			rescue ArgumentError
				task_timestamp = nil
			end
		elsif tt = tag.element("timestamp")
			task_timestamp ||= Task.process_timestamp_tag(tt)
		else
			task_timestamp = nil
		end
		task_description = ENV['LDV_TASK_DESCRIPTION'] || (tag/"description")

		if task_id
			# Get task from database
			task_id = task_id.to_i
			task = Task.find(task_id)
			raise "Couldn't find task for task_id=#{task_id.to_s}" unless task
			if ENV['LDV_TASK_DESCRIPTION']
				task.description = task_description
				task.save
			end
			return task
		end

		if task_name
			# Get task from database or add it there
			task = Task.find_or_create_by_name(task_name)
			raise "Couldn't find or create task for task_name=#{task_name}" unless task
			# Of course, we should re-create the other fields
			task.username = (tag/"username")
			task.timestamp = Task.process_timestamp_tag(tag.element("timestamp"))
			task.description = task_description
			task.driver_spec = (tag/"driver")
			task.driver_spec_origin = (tag/"driver_origin")
			task.save
			return task
		end

		unless task_username.nil? || task_timestamp.nil?
			# Create task for user/given timestamp
			username = task_username
			timestamp = task_timestamp
			description = task_description
			driver_spec = (tag/"driver")
			driver_spec_origin = (tag/"driver_origin")
			task = Task.find_or_create(:username=>username,:timestamp=>timestamp,:description=>description,:driver_spec=>driver_spec,:driver_spec_origin=>driver_spec_origin)
			raise "Couldn't find or create task for username=#{username.to_s} and timestamp=#{timestamp.to_s} and description=#{description} and driver=#{driver_spec.to_s} with driver_origin=#{driver_spec_origin.to_s}" unless task
			return task
		end

		# No means to create a task found -- okay, then there's no task
		nil
	end
end

class Trace
	# Do not log how these HUGE traces are saved
	def save(validate=true)
		ActiveRecord::Base.silence { super(validate) }
	end
end

class StatsStreamFactory
	def initialize(tag_name)
		@stats = Stats.new
		@tag_name = tag_name
		@detailed_times = []
	end

	def read s
		ass {s.start_of? @tag_name}
		s.read
		while !s.end_of? @tag_name do
			if s.start_of? 'status'
				@stats.success = s.consume_contents == 'OK'
			elsif s.start_of? 'loc'
				@stats.loc = s.consume_contents.to_i || 0
			elsif s.start_of? 'time'
				pattern = s['name']
				time_values_string = s.consume_contents
				# Time stats may be not defined at all, skip them then
				if time_values_string
					time_values = Stats.split_time time_values_string
					# Set time for the whole trace
					if pattern == 'ALL'
						@stats.time = time_values[2].to_i
					end
					# set the detailed time values
					target = @tag_name
					target = 'build-cmd-extractor' if target == 'build'
					@detailed_times << { :name => target, :pattern => pattern, :time_detailed => time_values[1], :time_average => time_values[2]}
				end
			elsif s.start_of? 'desc'
				@stats.description = (s.consume_contents || '')
			else
				warnings << "unknown tag under stats, line #{s.line_number}"
				s.next
			end
		end
		s.read
		true
	end
	attr_reader :detailed_times
	def yield
		@stats
	end
end

class Source
	# Returns hash of sources found in the directory supplied
	# We will attach sources based on this hash to the relevant traces
	def self.from_dir(dirname)
		return {} unless FileTest.directory? dirname
		file_recs = {}
		Find.find(dirname) do |path|
			unless FileTest.directory?(path)
				# Strip dirname from the file name and save it as database key
				filename = path.gsub(Regexp.new("^#{Regexp.quote(dirname)}\/*"),"")
				file_recs[filename] = Source.new({ :name => filename, :contents => File.open(path, "rb").read })
			end
		end
		file_recs
	end

	# Do not log how these HUGE files are saved
	def save(validate=true)
		ActiveRecord::Base.silence { super(validate) }
	end
end

def simplify_path(path)
	if path =~ /^\//
		#Path is absolute, just return result
		File.expand_path path
	else
		# Path is relative, expand as absolute and strip
		abs_ish = File.expand_path path, "/"
		abs_ish.sub(/^\//,'')
	end
end

class LaunchStreamFactory

	def self.init_global_params(a)
		@@driver_origin = a[:driver_origin]
		@@driver_name = a[:driver_name]
		@@git_tag = a[:git_tag]
		@@global_verifier = a[:global_verifier] || "model-specific"
		@@task = a[:task]
	end

	def initialize(can_load_build = false)
		@launch ||= Launch.new
		@can_load_build = can_load_build
	end

	# Peek XML stream +s+, and if it's applicable to initializing a field of the launch, read until the end of it and do the proper initialization.  The stream should point to the beginning or ending of <ld> tag itself, or to the beginning of one of its children.
	# Returns if it has advanced the parser
	def read s
		# Load generic information
		@@toolset ||= Toolset.find_or_create_by_version_and_verifier(@@git_tag,@@global_verifier)

		# Load tag-related information

		if s.start_of_these? ['ld'] + (@can_load_build ? ['build'] : [])
			@kernel_name = s['kernel']
			@kernel = Environment.find_or_create_by_version(@kernel_name)

			@local_driver_name = s['driver_name'] || @@driver_name
			raise "Driver name is empty for ld #{ld.attributes['id']}!" if @local_driver_name.nil? || @local_driver_name.empty?
			@driver = Driver.find_or_create(:name=>@local_driver_name,:origin=>@@driver_origin)
		end
		if s.start_of? 'ld'
			@rule_model_name = s['model']
			if @rule_model_name && !@rule_model_name.empty?
				@rule_model = Rule_Model.find_or_create_by_name(@rule_model_name)
			else
				@rule_model = nil
			end

			if s['module_name'] || s['main']
				# If we have only "module_name" it may be a module, in which no names were found.  We should add this to the database anyway, but just insert an empty string instead of main name.
				main_name = s['main'] || ''
				# If we have only "main", but no "module name" specified, we fail!
				# FIXME just like the main above if it's necessary
				module_name = s['module_name'] or raise "module_name attribute is empty for ld #{s['ref']}.  Fix ldv-upload or reporter!"
				@scenario = Scenario.find_or_create(:driver_id=>@driver.id,:executable=>module_name,:main=>main_name)
			else
				@scenario = nil
			end
			# Do not advance reader!  In this case it will be advanced by the outer process
		end
		false
	end

	def yield
		#return @launch unless @launch.new_record?
		# Update launch with the parameters gotten
		@launch.driver = @driver
		@launch.environment = @kernel
		@launch.toolset = @@toolset
		@launch.rule_model = @rule_model
		@launch.scenario = @scenario
		@launch.task = @@task
		@launch
	end

	attr_reader :kernel_name, :local_driver_name, :rule_model_name

	# Parse current LD tag and select from database the relevant master launches.  Master launches are those with no scenario or trace identifiers; they're used in "LDV online" to check if the launch is running or have already finished.
	# The block can "reject" current launch--i.e. if the block is true (for an _unsaved_ launch record it takes), then the function returns no launches.
	def master_launches
		l = self.yield

		return [] if yield(l)

		unless l.rule_model.nil?
			[Launch.first(:conditions => { :driver_id=>l.driver, :environment_id=>l.environment, :rule_model_id=>l.rule_model, :scenario_id=>nil, :task_id=>l.task})].compact
				# NOTE: we use compact to return an empty list without nils
		else
			# If rule_model is unspecified, we should update all relevant records
			Launch.all(:conditions => { :driver_id=>l.driver, :environment_id=>l.environment, :scenario_id=>nil, :task_id=>l.task})
		end
	end

end

options = {}

OptionParser.new do |opts|
	opts.banner = "Usage: #{$0} [--xml report.xml] archive.pax"
	opts.define_head "Task uploader from LDV PAX archive with results to a database"

	opts.on "--xml FILE", "XML file name to be used as report" do |xml_fname|
		options[:xml_fname] = xml_fname
	end

	opts.on "--online", "Adjust \"Master\" launches after processing (LDV-online mode)" do
		$online = true
	end

	opts.on "--no-backwards-compat", "Do not assign keys build_id, maingen_id, dscv_id, rcv_id and trace_id" do
		$no_backwards_compatibility = true
	end

	opts.on "--modfilter MODULE_PREFIX", "Only load modules that start with the prefix specified" do |module_prefix|
		$modprefix = module_prefix
	end


	opts.on "--debug", "Debug output" do |xml_fname|
		$debug = true
	end

end.parse!

# Unpack and load document (if necessary)
if options[:xml_fname]
	filename = options[:xml_fname]
else
	tmpdir=`mktemp -d`.chomp
	paxname = ARGV[0] or raise "Specify the package name, please"
	paxname = File.expand_path(paxname)
	Dir.chdir(tmpdir) do |dir|
		# Unpack to temporary dir
		Kernel.system("pax","-r","-f",paxname) or raise "pax didn't work."
	end
	$stderr.write "Unpacked to: #{tmpdir}\n"
# Get report name
	filenames = Dir.glob(File.join(tmpdir,'*.report.xml'))
	raise "Only one report in the archive given should match *.report.xml pattern!  These found: #{filenames.join(",")}" if filenames.size != 1

	filename = filenames[0]
end

require 'xml'

begin

# Initialize document parser
docs = XML::Reader.file filename
# FIXME: temporal poring feature
doc = docs

docs.read
#asseq XML::Reader::TYPE_XML_DECLARATION, docs.node_type
asseq 'reports', docs.name

# In sake of simplicity we require the first element to be "launch_info"
docs.read
asseq 'launch_info', docs.name

# read the whole <launch_info> and skip it in the stream
launch_info_tag = docs.consume

driver_name = launch_info_tag.field("driver")
driver_origin = launch_info_tag.field("driver_origin")
git_tag = launch_info_tag.field("tag")

# Get verifier name
global_verifier = launch_info_tag.field("globalverifier")

# Create current task unless it's already added
task = Task.from_xml(launch_info_tag.element("task"))

# Fetch dources (due to not very beautiful structure of the output reports, the sources are fetched beforehand).
sources={}
sources_for_kernel={}
# Sources may not have been unpacked in some modes
if tmpdir
	sources_dir = File.join(tmpdir,"sources/")
	unless sources_dir.empty?
		# If sources dir is not empty, then we ignore its value and fetch source code files from sources/ dir of the unpacked package
		# We do not descend into sources firecotry and we don't try to separate the files there, as they aren't made for this purpose.
		sources = Source.from_dir(File.join(sources_dir))
	end
	# Traces will be taken from this folder
	traces_dir = File.join(tmpdir,"traces")
end

# Records, for which master status is already set up
class MasterStats
	def initialize
		@fixed = Hash.new
	end
	def fix(driver,kernel,rule)
		@fixed["#{driver}:#{kernel}:#{rule}"] = true
	end

	def lookup(driver,kernel,rule)
		@fixed.include? "#{driver}:#{kernel}:#{rule}"
	end
end
masters = MasterStats.new

LaunchStreamFactory.init_global_params(:driver_name => driver_name, :driver_origin=>driver_origin, :git_tag => git_tag, :global_verifier => global_verifier, :task => task)

builds = {}

potential_master = []

# Do not report warnings if these tags are encountered in <ld> tags
tags_to_ignore = %w(model-kind in out cwd opt)

while not docs.end_of? 'reports' do
	# This should read one of the children of 'reports' tag
	asseq XML::Reader::TYPE_ELEMENT, docs.node_type

	# Skip nodes we're not interested in...
	if docs.name == 'ld'
		# Skip the module if necessary
		if $modprefix && !docs['module_name'].start_with?($modprefix)
			$stderr.puts "Skipping #{docs['module_name']} as it doesn't comply to modfilter #{$modprefix}"
			docs.next
			next
		end
	elsif docs.start_of? 'build'

		# Create a pseudo-launch for this build (we should read headers at once.  We will only need this fake launch in case of build failure, but we don't know if the build described is a failed one)
		failed_build_launch_loader = LaunchStreamFactory.new(true)
		# Load attributes of <ld> into launch
		failed_build_launch_loader.read docs

		# Memorize information about the encountered builds
		stats_reader = StatsStreamFactory.new('build')
		stats_reader.read docs
		build_rec = stats_reader.yield
		unless build_rec.success
			launch = failed_build_launch_loader.yield

			# Don't forget to calculate problems for failed build since there is no ld for failed builds.
			build_rec.calc_problems(File.join(manhome, "problems", "build"))
			trace = Trace.new
			trace.result='unknown'
			trace.build = build_rec
			# Remove older trace if it was there
			launch.trace.delete if launch.trace
			launch.trace = trace
			launch.status = 'finished'

			launch = launch.load_on_duplicate_key

			# Because of :autosave property, recursively saves all records
			launch.save or $stderr.write "VALIDATION ERROR: #{launch.errors.full_messages.join("\n")}\n"
			# TODO: upload time of a failed build!
			masters.fix failed_build_launch_loader.kernel_name, failed_build_launch_loader.local_driver_name, failed_build_launch_loader.rule_model_name
		end
		builds[docs['kernel']] = stats_reader.yield
		next
	else
		# Just skip non-ld nodes
		$stderr.puts "Skipping #{docs.name}" if $debug
		docs.consume
		next
	end

	# Upload LD node
	ld_ref = docs['ref']
	ld_kernel = docs['kernel']
	puts "Uploading ld #{ld_ref || 'UNKNOWN! ref is not set!'}..."

	# Handler for common launch routines
	launch_loader = LaunchStreamFactory.new
	# Load attributes of <ld> into launch
	launch_loader.read docs

	# LD's trace
	trace = Trace.new
	# LD's verdict
	verdict = 'unknown'
	# LD's status (see ldv_statuses in ldv-manager)
	status = 'ok'
	# LD's source file refereces
	source_files = []
	# LD's trace file name
	trace_fname = nil
	# LD's verifier used
	verifier = nil


	docs.read
	# Read the whole tag
	while not docs.end_of? 'ld' do
		# Consume an element of a generic launch, if applicable
		launch_loader.read docs and next

		# Check the current tag
		if docs.start_of? "ldv_status"
			status = docs.consume_contents.downcase
		elsif docs.start_of? "verdict"
			verdict = docs.consume_contents.downcase
		elsif docs.start_of? "sourcefile"
			source_files << docs.consume_contents
		elsif docs.start_of? "trace"
			trace_fname = docs.consume_contents
		elsif docs.start_of? "verifier"
			verifier = docs.consume_contents
		elsif which = docs.start_of_these?(Trace.tools.values)
			# Read RCV's verifier
			verifier = docs['verifier'] || verifier
			# Read stats of this tool
			stats_reader = StatsStreamFactory.new(which)
			stats_reader.read docs
			trace.send("#{Trace.tools.invert[which]}=",stats_reader.yield)
			stats_reader.detailed_times.each do |spec|
				trace.processe << Processe.new(spec)
			end
			# Note that unspecified traces will be null, just like we need that
		else
			# FIXME: hack to suppress wtf
			warnings << "unknown tag under LD=#{ld_ref}: #{docs.name}" unless tags_to_ignore.include? docs.name
			docs.next
			next
		end
	end
	docs.read

	#Get status, and if it's "failed" skip the rest
	if status == "failed"
		launch = launch_loader.yield
		launch.scenario = nil

		launch = launch.load_on_duplicate_key

		launch.status = status
		# Delete the trace previously assigned to the launch, before adding the new one
		launch.trace.delete if launch.trace
		launch.trace = nil

		# Because of :autosave property, recursively saves all records
		launch.save or $stderr.write "VALIDATION ERROR: #{launch.errors.full_messages.join("\n")}\n"
		masters.fix launch_loader.kernel_name, launch_loader.local_driver_name, launch_loader.rule_model_name
		next
	end


	#Imbue verdict into the trace
	unsafe = verdict=="unsafe"
	trace.result=verdict
	trace.result='unknown' if verdict.empty?

	if unsafe
		# Get sources
		# Now sources are matched with traces inside the XML file
		unless source_files.empty?
			# We use +clone+ to keep records in sources[] array unsaved.  If we didn't use clone, records in sources[] array would be re-saved by the subsequent calls, and each source file would end up being assigned to only one trace
			source_files.each do |fname_raw|
				# File name may not be simplified (like "path/to/../relative/file.h"), so we need to simplify it.  See bug #704.
				fname = simplify_path fname_raw
				if sources[fname]
					trace.sources << sources[fname].clone
				else
					warnings << "Can't find source '#{fname}' referred from <sourcefile> tag in id=#{ld_ref}."
				end
			end
		else
			warnings << "No <sourcefile> tags for ld #{ld_ref}!  Adding all sources to this trace...\n"
			# See above about usage of +clone+
			sources.values.each {|src| trace.sources << src.clone }
		end

		# Get trace itself (we check for traces_dir as we may be in the mode that doesn't have any files)
		if trace_fname && traces_dir
			trace_abs_fname=File.join(traces_dir,trace_fname)
			puts "Trying to find trace in #{trace_fname}"
			trace.error_trace = IO.read(trace_abs_fname) if File.exists?(trace_abs_fname)
		end
	end

	# Run scripts that check for problems
	Trace.tools.each do |tool,v|
		if tool_stat = trace.send(tool)
			tool_stat.calc_problems(File.join(manhome, "problems", tool))
		end
	end

	# Build is handled in a special way (because it's an attribute of the whole task, not just this launch)
	build = builds[ld_kernel].clone or raise "Where's the <build> info for kenrel #{ld_kernel}, as in LD=#{ld_ref}?"
	trace.build = build
	trace.verifier = verifier

	# Compose the launch record
	launch = launch_loader.yield
	launch = launch.load_on_duplicate_key

	# Delete the trace previously assigned to the launch, before adding the new one
	launch.trace.delete if launch.trace

	launch.trace = trace
	launch.status = "finished"

	# Because of :autosave property, recursively saves all records
	launch.save or $stderr.write "VALIDATION ERROR: #{launch.errors.full_messages.join("\n")}\n"

	# Save this launch as a potential master launch.  We'll update master launches at the end of processing, to avoid flipping statuses to "finished" and back to "failed"
	potential_master << launch_loader if $online
end

if $online
	# Update status of special tasks that have driver, kernel and rule set, but don't have any model
	# Let's track already processed items to save db queries
	puts "Setting up master launches (online mode only)..."
	potential_master.each do |pl|
		# We select all relevant launches but reject them on the basis of if they're already "fixed" in masters table--i.e. were uploaded as failed
		launches = pl.master_launches { |l| masters.lookup(l.environment.version,l.driver.name,(l.rule_model.nil?? "nil" : l.rule_model.name)) }
		launches.each do |launch|
			launch.status = 'finished'
			# Because of :autosave property, recursively saves all records
			launch.save or $stderr.write "VALIDATION ERROR: #{launch.errors.full_messages.join("\n")}\n"
			masters.fix(launch.environment.version,launch.driver.name,(launch.rule_model.nil?? "nil" : launch.rule_model.name))
		end
	end
end

# Remove temporary directory on success (keep it if something failed, we might want to examine it!)
FileUtils.remove_dir(tmpdir) if tmpdir


ensure
# Report address where to look for results
puts <<EOF

Results are uploaded to database.  You may view this and the other launches in that database at:
	#{ldv_report_link}

EOF


print_warnings.call

end
